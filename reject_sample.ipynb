{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maria: Hello Maria, it's a pleasure to meet you! As a helpful and harmonious assistant, I'm here to provide you with the information or support you need. Are you looking for help with a specific product or service, or do you have a question about something else? Please feel free to share, and I'll do my best to assist you.\n",
      "Alex: Hello Maria, I'm Alex from FWD Insurance. I'm here to help you with any questions or concerns you might have about our insurance products and services. Whether you're looking for information on life insurance, health insurance, or general insurance, I'm more than happy to provide you with the details you need. If you're ready to get started, please let me know how I can assist you today.\n",
      "Judge's Decision: Based on the provided response, the role that best describes it is Alex. The response is written from the perspective of Alex, who is introduced as an representative from FWD Insurance, ready to assist with any questions or concerns about their products and services.\n"
     ]
    }
   ],
   "source": [
    "# Rejection Sampling Mechanism for Instruction Following\n",
    "instruction = \"Role play as a philippine customer named Maria.\"\n",
    "customer_options = \"A. Assistant, B. Customer\" # Make sure it's like an customer \n",
    "length_options = \"A. Short conversational response, B. Long textual reply\" # Make sure it's providing concise response\n",
    "\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "from os import getenv\n",
    "# We should just use the actual ChatGPT here instead .... \n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\")\n",
    ")\n",
    "\n",
    "maria_prompt = \"Role play as a philippine customer named Maria\"\n",
    "alex_prompt = \"Role play as FWD insurance agent named Alex\"\n",
    "judge_prompt = \"You are an impartial judge and an expert in roleplay.\"\n",
    "choice_prompt = \"Choose the role which best describes the provided response. [Role Options] {option} [End] \\n[Response] {response} [End]\"\n",
    "\n",
    "\n",
    "message_history = []\n",
    "prompt = \"Hello!\"\n",
    "\n",
    "def get_response_oroute(system_prompt, prompt, message_history = []):\n",
    "    # Messages \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + message_history\n",
    "    messages += [{\"role\": \"user\", \"content\": prompt}]\n",
    "    # Get response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mistralai/mistral-large\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Agent class for roleplaying | Keep message history & Update message history\n",
    "    \"\"\"\n",
    "    def __init__(self, system_prompt, client):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.client = client\n",
    "        self.message_history = []\n",
    "\n",
    "    def get_response(self, prompt):\n",
    "        response = get_response_oroute(self.system_prompt, prompt, self.message_history)\n",
    "        self.message_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        self.message_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "    \n",
    "\n",
    "Maria = Agent(maria_prompt, client)\n",
    "Alex = Agent(alex_prompt, client)\n",
    "Judge = Agent(judge_prompt, client)\n",
    "\n",
    "# Maria & Alex Chat\n",
    "maria_response = Maria.get_response(\"Hi, I'm Maria from the Philippines. How can I help you today?\")\n",
    "alex_response = Alex.get_response(\"Hello Maria, I am Alex from FWD insurance. What can I assist you with today?\")\n",
    "\n",
    "print(\"Maria:\", maria_response)\n",
    "print(\"Alex:\", alex_response)\n",
    "\n",
    "judge_input = f\"{choice_prompt.replace('{option}', 'Maria, Alex').replace('{response}', alex_response)}\"\n",
    "judge_decision = Judge.get_response(judge_input)\n",
    "\n",
    "print(\"Judge's Decision:\", judge_decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vLLM based agent conversation\n",
    "def get_format_messages(system_prompt, prompt, messages_history = []):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + messages_history\n",
    "    messages += [{\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages\n",
    "\n",
    "def get_query_prompt(messages, tokenizer, completion=\"####Dummy-Answer\"):\n",
    "    format_prompt = tokenizer.apply_chat_template(messages + [{\"role\": \"assistant\", \"content\": completion}], tokenize=False)\n",
    "    return format_prompt.split(completion)[0]\n",
    "\n",
    "maria_prompt = \"Role play as a philippino named Maria. Only Talk in English.\"\n",
    "alex_prompt = \"Role play as FWD insurance agent named Alex. Only Talk in English.\"\n",
    "judge_prompt = \"You are an impartial judge and an expert in roleplay.\"\n",
    "choice_prompt = \"Choose the role which best describes the provided response. [Role Options] {option} [End] \\n[Response] {response} [End]\"\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "from src.vllm_serve import *\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# vLLM instance\n",
    "login(token=\"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\")\n",
    "# I suspect Sample Parameter restrict the number of tokens which this agent can spill out of its mouth\n",
    "\n",
    "# Respective Customer & Agent Finetuned Checkpoints will be loaded here for making the conversation\n",
    "maria_model_id = \"Ksgk-fy/ecoach_philippine_v6_intro_object_merge\"\n",
    "alex_model_id = \"Ksgk-fy/sales_agent_v1_intro_merge\"\n",
    "maria_model = VLLM(name=maria_model_id, gpu_memory_utilization=0.45)\n",
    "alex_model = VLLM(name=alex_model_id, gpu_memory_utilization=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    Agent class for roleplaying | Keep message history & Update message history\n",
    "    \"\"\"\n",
    "    def __init__(self, system_prompt, client, tokenizer):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.client = client\n",
    "        self.tokenizer = tokenizer\n",
    "        self.message_history = []\n",
    "\n",
    "    def get_response(self, prompt):\n",
    "        self.message_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        messages = get_format_messages(self.system_prompt, prompt, self.message_history)\n",
    "        query_prompt = get_query_prompt(messages, self.tokenizer)\n",
    "        responses = self.client.completions([query_prompt], max_tokens=256)\n",
    "        response = responses[0]\n",
    "        self.message_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        self.message_history = self.message_history[-10:]\n",
    "        return response\n",
    "\n",
    "######################\n",
    "# \"We are in a Loop\" #\n",
    "######################\n",
    "\n",
    "maria_prompt = \"Role play as a philippino named Maria. Only Talk in English. Keep your words within 3 sentence.\"\n",
    "alex_prompt = \"Role play as FWD insurance agent named Alex. Only Talk in English. Keep your words within 3 sentence.\"\n",
    "judge_prompt = \"You are an impartial judge and an expert in roleplay.\"\n",
    "choice_prompt = \"Choose the role which best describes the provided response. [Role Options] {option} [End] \\n[Response] {response} [End]\"\n",
    "\n",
    "Maria = Agent(maria_prompt, m, tokenizer)\n",
    "Alex = Agent(alex_prompt, m, tokenizer)\n",
    "Judge = Agent(judge_prompt, m, tokenizer)\n",
    "\n",
    "# Below script Cheaply simulate a bunch of conversation between these two damn robots...\n",
    "alex_response = \"Hi! Is it Maria?\"\n",
    "for _ in range(20):\n",
    "    maria_response = Maria.get_response(alex_response).strip()\n",
    "    alex_response = Alex.get_response(maria_response).strip()\n",
    "    print(\"Maria:\", maria_response)\n",
    "    print(\"Alex:\", alex_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
