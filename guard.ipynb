{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a freakish classifier should not be that hard .....(Face Palm)\n",
    "\n",
    "# Build Embedding Model to classify OOC behaviors, using provided dataset \n",
    "from database.pro.clean import clean_response\n",
    "import glob \n",
    "import datasets \n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "txt_files = glob.glob(\"database/pro/transcript/transcript_*.txt\")\n",
    "label_map = {0: \"Agent\", 1: \"Customer\"}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Naive Bayes gives 93%+ Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Agent       0.93      0.87      0.90       456\n",
      "    Customer       0.90      0.95      0.92       567\n",
      "\n",
      "    accuracy                           0.91      1023\n",
      "   macro avg       0.92      0.91      0.91      1023\n",
      "weighted avg       0.91      0.91      0.91      1023\n",
      "\n",
      "Text:  Have you heard about FWD before?  | Prediction: Customer  | Confidence:  0.5984111122132806 | Ground Truth: Agent\n",
      "Text:  I work at FWD insurance  | Prediction: Customer  | Confidence:  0.8566138590075342 | Ground Truth: Agent\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = prepare_ooc_dataset(txt_files, cases)\n",
    "vectorizer, nb_classifier = train_nb(train_dataset, test_dataset)\n",
    "\n",
    "\n",
    "def check_performance(vectorizer, nb_classifier, cases, fn):\n",
    "    error_count = 0\n",
    "    for (text, label) in cases:\n",
    "        (pred, confidence) = fn(text, vectorizer, nb_classifier)\n",
    "        gt = label_map[label]  # Assuming all samples are \"Agent\" class\n",
    "        error = pred != gt\n",
    "        if error:\n",
    "            error_count += 1\n",
    "            print(\"Text: \", text, \" | Prediction:\", pred,\" | Confidence: \", confidence, \"| Ground Truth:\", gt)\n",
    "\n",
    "\n",
    "check_performance(vectorizer, nb_classifier, cases, fn=pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Classifier with Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/2: 100%|██████████| 288/288 [02:59<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Average Loss: 0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9668\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Agent       0.97      0.96      0.96       456\n",
      "    Customer       0.97      0.97      0.97       567\n",
      "\n",
      "    accuracy                           0.97      1023\n",
      "   macro avg       0.97      0.97      0.97      1023\n",
      "weighted avg       0.97      0.97      0.97      1023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 288/288 [03:00<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Average Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9677\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Agent       0.94      0.99      0.96       456\n",
      "    Customer       0.99      0.95      0.97       567\n",
      "\n",
      "    accuracy                           0.97      1023\n",
      "   macro avg       0.97      0.97      0.97      1023\n",
      "weighted avg       0.97      0.97      0.97      1023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = train_em(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da77236ffac4aa68fb1009690cbcca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ksgk-fy/ooc_patch_v1/commit/1d0926245491b21f2e2aeaff2c1e53ec43e0da88', commit_message='Upload tokenizer', commit_description='', oid='1d0926245491b21f2e2aeaff2c1e53ec43e0da88', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The push_to_hub function cannot be imported from huggingface_hub\n",
    "# If you need to upload the model to Hugging Face Hub, consider using\n",
    "# the `transformers` library's built-in methods or the `huggingface_hub`\n",
    "# library's alternative functions.\n",
    "\n",
    "# For example, you might use:\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "model.push_to_hub(\"Ksgk-fy/ooc_patch_v1\")\n",
    "tokenizer.push_to_hub(\"Ksgk-fy/ooc_patch_v1\")\n",
    "\n",
    "# Or, if you prefer to use huggingface_hub directly:\n",
    "# from huggingface_hub import HfApi\n",
    "# api = HfApi()\n",
    "# api.upload_file(\n",
    "#     path_or_fileobj=\"./patch_model/pytorch_model.bin\",\n",
    "#     path_in_repo=\"pytorch_model.bin\",\n",
    "#     repo_id=\"Ksgk-fy/ooc_patch_v1\",\n",
    "# )\n",
    "# Save the model and tokenizer locally\n",
    "# model.save_pretrained(\"./patch_model\")\n",
    "# tokenizer.save_pretrained(\"./patch_model\")\n",
    "\n",
    "# # Upload to Hugging Face Hub\n",
    "# push_to_hub(repo_id=\"Ksgk-fy/ooc_patch_v1\", local_dir=\"./patch_model\", use_auth_token=True)\n",
    "\n",
    "# print(\"Model and tokenizer uploaded to Hugging Face Hub successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f605256e138547a8ba365aedbe44fb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1051006c7ac64b729f91c1817c7a4582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e86a9087b8543d9a8207871f2e94d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0277063d19482d989c2a19238a0ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eea995928f7464c90f0d7b38aca9461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bfb7bec030487b9fa6dd8abdb36e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(repo_id)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Move the model to the appropriate device (CPU or GPU)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel and tokenizer loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "repo_id = \"Ksgk-fy/ooc_patch_v1\"\n",
    "# Load the model and tokenizer from the Hugging Face Hub\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(repo_id)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "label_map = {0: \"Agent\", 1: \"Customer\"}\n",
    "\n",
    "\n",
    "def predict_em(sample_text, model, tokenizer, threshold_agent=0, threshold_customer=0):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # Tokenize the sample text\n",
    "    encoded = tokenizer(sample_text, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        predicted_confidence = torch.nn.functional.softmax(logits, dim=1)[0][predicted_class].item()\n",
    "\n",
    "    # Map the predicted class to the corresponding label\n",
    "    label_map = {0: \"Agent\", 1: \"Customer\"}\n",
    "    thres_map = {0: threshold_agent, 1: threshold_customer}\n",
    "    if predicted_confidence < thres_map[predicted_class]:\n",
    "        return \"Not Sure\", 0\n",
    "    else:\n",
    "        predicted_label = label_map[predicted_class]\n",
    "        return predicted_label, predicted_confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  I am not interested in your insurance product  | Prediction: Not Sure  | Confidence:  0 | Ground Truth: Customer\n",
      "Text:  Can you explain the benefits of FWD insurance?  | Prediction: Not Sure  | Confidence:  0 | Ground Truth: Customer\n",
      "Text:  FWD seems like a reliable company.  | Prediction: Not Sure  | Confidence:  0 | Ground Truth: Customer\n",
      "Text:  Tell me more about FWD's customer service.  | Prediction: Not Sure  | Confidence:  0 | Ground Truth: Customer\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "cases = [    \n",
    "    (\"Have you heard of FWD before?\", 0),\n",
    "    (\"I am not interested in your insurance product\", 1),\n",
    "    (\"So what is the different between FWD insurance and others?\", 1),\n",
    "    (\"What is FWD again?\", 1),\n",
    "    (\"I do not trust FWD.\", 1),\n",
    "    (\"Hello Alex!\", 1),\n",
    "    (\"Can you explain the benefits of FWD insurance?\", 1),\n",
    "    (\"I'm looking for the best insurance coverage.\", 1),\n",
    "    (\"FWD seems like a reliable company.\", 1),\n",
    "    (\"What are the premiums for FWD insurance?\", 1),\n",
    "    (\"I've had bad experiences with insurance companies before.\", 1),\n",
    "    (\"Is FWD insurance available in my country?\", 1),\n",
    "    (\"How does FWD compare to other major insurers?\", 1),\n",
    "    (\"I'm satisfied with my current insurance provider.\", 1),\n",
    "    (\"Tell me more about FWD's customer service.\", 1)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def check_performance(model, tokenizer, cases, fn=predict_em):\n",
    "    error_count = 0\n",
    "    for (text, label) in cases:\n",
    "        (pred, confidence) = fn(text, model, tokenizer, 0.8, 0.)\n",
    "        gt = label_map[label]  # Assuming all samples are \"Agent\" class\n",
    "        error = pred != gt\n",
    "        if error:\n",
    "            error_count += 1\n",
    "            print(\"Text: \", text, \" | Prediction:\", pred,\" | Confidence: \", confidence, \"| Ground Truth:\", gt)\n",
    "\n",
    "\n",
    "check_performance(model, tokenizer, cases, fn = predict_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Have you heard of FWD before?  | Prediction: Customer | Ground Truth: Agent\n",
      "Text:  I work at FWD insurance  | Prediction: Customer | Ground Truth: Agent\n",
      "Total errors: 2\n",
      "Error Rate: 0.2857\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    \"Have you heard of FWD before?\",\n",
    "    \"I work at FWD insurance\",\n",
    "    \"FWD offers a wide range of insurance products to suit your needs.\",\n",
    "    \"Our policies are designed to provide comprehensive coverage at competitive rates.\",\n",
    "    \"Would you like to know more about our life insurance options?\",\n",
    "    \"FWD has been in the insurance industry for over a decade, serving millions of customers.\",\n",
    "    \"We pride ourselves on our customer-centric approach and innovative digital solutions.\",\n",
    "]\n",
    "\n",
    "# Inference and accuracy check\n",
    "error_count = 0\n",
    "for sample_text in sample_texts:\n",
    "    pred = predict_em(sample_text, model, tokenizer)\n",
    "    gt = \"Agent\"  # Assuming all samples are \"Agent\" class\n",
    "    error = pred != gt \n",
    "    if error:\n",
    "        error_count += 1\n",
    "        print(\"Text: \", sample_text, \" | Prediction:\", pred, \"| Ground Truth:\", gt)\n",
    "\n",
    "print(f\"Total errors: {error_count}\")\n",
    "error_rate = error_count / len(sample_texts)\n",
    "print(f\"Error Rate: {error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text: 'Have you heard of FWD before?'\n",
      "Predicted label: Customer\n",
      "Confidence: 0.76\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 26\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(label)\n\u001b[1;32m     22\u001b[0m         }\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create an instance of the dataset\u001b[39;00m\n\u001b[1;32m     25\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TextClassificationDataset(\n\u001b[0;32m---> 26\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtrain_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     27\u001b[0m     labels\u001b[38;5;241m=\u001b[39mtrain_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     28\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     29\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Print some information about the dataset\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of samples in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m, in \u001b[0;36mTextClassificationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 15\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts[idx]\n\u001b[1;32m     16\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     17\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "# Create an instance of the dataset\n",
    "train_dataset = TextClassificationDataset(\n",
    "    texts=train_dataset[\"text\"],\n",
    "    labels=train_dataset[\"label\"],\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(f\"Number of samples in the dataset: {len(train_dataset)}\")\n",
    "print(f\"Sample from the dataset: {train_dataset[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(texts)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
